---
title: "introduction"
author: "陈洁一稿，杨品修改"
date: "2019年5月29日"
output: html_document
---
# 第1章 导论

## 1.1统计学习概述

统计学习是一套以**理解数据**为目的的庞大工具集。其工具可分为两大类：

* **有指导的**学习

&emsp;&emsp;有指导的统计学习工具主要有两种用途:一是面向预测的统计模型的建立，二是对一个或多个给定的输入估计某个输出。

* **无指导的**学习

&emsp;&emsp;在无指导的统计学习问题中，有输入变量但不指定输出变量，建模的主旨是学习数据的关系和结构。

### 1.1.1工资数据
Wage数据集考察与美国中部大西洋地区男性收入相关的几个因素。具体来说，我们希望理解员工的age（年龄）、education（受教育程度）、year（工龄）与其历年wage（工资）的关系。

![图1-1](http://i2.tiimg.com/611786/bc1b48d60ec9be4c.png)

观察图片，左图绘制了每个人的wage与age的关系图，平均来看，随着age的增长wage是增加的，这种趋势在60岁左右终止，之后wage开始下降。中图是wage和year的函数关系图，呈现出缓慢而稳定的增长。右图：箱线图反映了wage和education的函数关系，wage随受教育水平呈现递增关系，说明一个人有较高的教育水平，其工资水平也一般较高。由此可见，要想准确预测一个人的wage，应该结合这个人的年龄、工龄和受教育水平来分析。

### 1.1.2金融市场数据
Wage数据中的输出变量数据类型是连续型，也称为定量型。这类问题通常称为**回归**(regression) 问题。但在某些情况下，我们可能需要预测一个非数值变量，即分类或定性的输出。如图，我们将考察一个股票市场数据集（Smarket），该数据集收集了2001年至2005年间5年期的标准普尔500股票指数每日股指变动数据。这个数据的目标是用过去5天指数的变动比例预测5天后股指的涨跌状态。这个问题中的统计学模型不是对数值类型的变量预测，而是关注某一天的股市业绩是掉进Up桶还是Down桶。这类问题称为**分类**(classification) 问题。

![图1-2](http://i2.tiimg.com/611786/ccf5fad1ab72aa10.png)

左侧绘制了两张箱线图分别是股指相对于前一天的百分比变化情况:一张是648天市场股指上涨的分布，另一张是602天市场股指下降的情况，两图相比无明显不同，说明只是用前一天S&P股指变动很难产生预测策略。另外两张箱线图分别显示了用2天前和3天前股指百分比变化预测当期，同样未能反映出过去和当期回报之间的关联性。这种差异模式不显著应该是预料之中的，如果相连几天的投资回报能够存在很强的关系的话，那么通过一个简单的交易策略，就可以从市场中赢的利润。

### 1.1.3基因表达数据
上述两个应用的数据集中既有输入变量也有输出变量,然而还有一类不同的重要问题，即观察到的只有输入变量没有相应的输出变量。这里以基因表达数据集（NCI60）为例，其中包含了64个癌症细胞系6830个基因表达测量数据，我们不是要对某个指定的输入预测，而是在基因表达测量上的细胞系数据中看是否有集群存在，称这类问题为**聚类**(clustering)问题。这64个细胞系可以通过两个变量$Z_{1}和Z_{2}$来表达，这两个变量是数据中的前两个**主成分**(principal component)，综合了各个细胞系6830个基因表达测量信息。虽然降维可能导致部分信息缺失，但却能为验证聚类合理性进行可视化分析。

![图1-4](http://i2.tiimg.com/611786/f43bbd7130e9abd7.png)

聚类问题的难点是聚类数的确定，而通过观察左图，至少说明数据中存在4个细胞系组，图中以不同颜色区分。右图数据的表示方式与左图同理，对14种不同的癌症使用了不同的颜色标记出来。图上清晰地表明同类型癌症的细胞系在这两个特定的二维坐标系上位置较为接近。综上所述，即使在没有癌症信息参与的情况下，左图的聚类结果依然能够将右图中实际的癌症类型所蕴含的相似特征诠释出来。这个例子反映出聚类区别于有指导方法逼近真实的分析能力。

## 1.2统计学习简史
统计学习是一个比较新的名词，但该领域中的许多方法实际上很早以前就已成型。



![history](E:\\Book\history.png)

## 1.3关于这本书
2001年由哈斯帖(hastie)、提布施瓦尼(Tibshirani)和弗里德曼(Friedman) 编著了《统计学习基础》(ESL)。该书自出版之日起，很长一段时间以来一直被誉为统计机器学习的奠基之作。《统计学习导论》(ISL)一书的写作目的在于加速统计学习从学术圈向主流领域的融合。无论是在选材的数量上，还是在方法的深度或是在内容表述的细节方面，ISL都不打算取代ESL。我们认为ESL更适用于专业人士，他们需要了解统计学习方法背后的技术细节。然而统计学习技术的用户社区已扩展至个体用户，他们有着更广泛的兴趣和背景。因此，我们相信他们现在正需要这样一方土壤——另一个版本的 ESL，可以不那么注重技巧却更引人入胜。
本书的写作意图是基于以下4方面的认识：

1. 许多统计学习方法不仅仅属于统计学科，而是在许多学术和非学术的领域里有广泛的应用。

2. 统计学习并非一组黑箱。

3. 尽管掌握组合模型中每个齿轮的功能至关重要，但这并不表示没有掌握理论细节就不能在箱子里构造机器!

4. 假定读者有志于应用统计学习方法解决现实世界的问题。

## 1.4这本书适用的读者群
本书适用于旨在运用现代统计学方法从数据中建模和进行预测的读者

## 1.5记号与简单的矩阵代数
&emsp;&emsp;记号中，$n$表示不同数据点或样本观测的个数；$p$表示用于预测的变量个数。

&emsp;&emsp;一般地，$x_{ij}$代表第$i$个观测的第$j$个变量值,$i = 1,2,{\ldots}, n;j = 1,{\ldots},p$。在本书中，$i$用于索引样本或观测（从1到$n$），$j$用于索引变量（从1到$p$）。$\bf{X}$则是$(i,j)$上元素为$x_{ij}$的$n\times{p}$矩阵即

$$
      {\bf{X}}=\begin{pmatrix}
      x_{11} & x_{12} & \cdots & x_{1p} \\
      x_{21} & x_{22} & \cdots & x_{2p} \\
      \vdots & \vdots & \ddots & \vdots \\
      x_{n1} & x_{n2} & \cdots & x_{np} \\
      \end{pmatrix}
$$
对矩阵不熟悉的读者，可将$\bf{X}$看成$n$行$p$列的表格。

&emsp;&emsp;有时会对$\bf{X}$的行进行研究，通常将行记为$x_1,x_2,{\ldots},x_n$。这里$x_i$是长度为$p$的向量，是第$i$个观测的$p$个变量测量，即

$$
    {x_i}=\begin{pmatrix}
    x_{i1} \\
    x_{i2} \\
    \vdots \\
    x_{ip} \\
    \end{pmatrix}
$$
（向量默认用列表示。）例如，对于 Wage数据集，$x_i$是一个长度为 12 的向量，包含第$i$个个体的year(年份)、age(年龄)、wage(工资)和其他变量值。有时也会研究$\bf{X}$的列，将其写作$x_1,x_2\cdots\ x_p$。它们都是长度为$n$的向量，即

$$
    {x_j}=\begin{pmatrix}
    x_{1j} \\
    x_{2j} \\
    \vdots \\
    x_{nj} \\
    \end{pmatrix}
$$
例如，Wage数据集中，$x_1$包含year（年份）的n=3000个观测值。

&emsp;&emsp;按这个记号，矩阵$\bf{X}$可以写成
           $$\bf{X}=(x_1\ x_2\cdots\ x_p)$$
或
$$
        {\bf{X}}=\begin{pmatrix}
        x_{1}^T \\
        x_{2}^T \\
        \vdots \\
        x_{n}^T \\
        \end{pmatrix}
$$
右上角记号$T$表示矩阵或向量的转置。例如${x_i}^T=(x_{i1}\ x_{i2}\cdots\ x_{ip})$,以及
$$
        {\bf{X}^T}=\begin{pmatrix}
        x_{11} & x_{21} & \cdots & x_{n1} \\
        x_{12} & x_{22} & \cdots & x_{n2} \\
        \vdots & \vdots & \ddots & \vdots \\
        x_{1p} & x_{2p} & \cdots & x_{np} \\
        \end{pmatrix}
$$
&emsp;&emsp;$y_i$表示待预测的变量(比如wage) 的第$i$个观测值。待预测变量全部 $n$个观测值的集合用如下向量表示:
$$
        {\bf{y}}=\begin{pmatrix}
        y_{1} \\
        y_{2} \\
        \vdots \\
        y_{n} \\
        \end{pmatrix}
$$
观测数据集为$\lbrace(x_1,y_1),(x_2,y_2),\cdots,(x_n,y_n)\rbrace$，其中$x_i$都是长度为$p$的向量。（若$p=1$，则$x_i$是标量。）

&emsp;&emsp;在本书中，长度为$n$的向量均用小写加粗字母表示，例如：
$$
        {\bf a}=\begin{pmatrix}
        a_1 \\
        a_2 \\
        \vdots \\
        a_n \\
        \end{pmatrix}
$$
但长度不为$n$的向量则用小写常规字母表示，例如$a$。标量也用小写常规字母表示，例如$a$。在极少数情况下，小写常规字母的两种不同用了两种不同用法会导致含义不明，当出现这一问题时，书中会加以说明。矩阵用加粗大写字母表示，例如$\bf{A}$。随机变量不论维数，一律用大写常规字母表示，例如$A$。

&emsp;&emsp;有时需要指出对象的维数。记号$a\in{\Bbb R}$说明某个对象是标量（若长度为$n$,则用$a\in{\Bbb R}^n$表示）。$a\in{\Bbb R}^k$说明某对象为向量，其长度为$k$。$\bf{A}\in{\Bbb R}^{r\times s}$则说明矩阵的维数是$r\times s$。

&emsp;&emsp;我们尽可能地避免矩阵代数的使用。但在少数情况下，完全回避矩阵代数会使计算变得缓慢冗长。在这些情况下，理解矩阵乘法的概念是很重要的。$\bf{A}\in{\Bbb R}^{r\times d}$，$\bf{B}\in{\Bbb R}^{d\times s}$。则$\bf{A}$与$\bf{B}$相乘的结果记为$\bf{AB}$。矩阵$\bf{AB}$的第$(i,j)$个元素等于$\bf{A}$中的第$i$行和$\bf{B}$中的第$j$列的对应元素乘积之和。即$(\bf{AB})_{ij}=\sum_{k=1}^d a_{ik}b_{kj}$。

## 1.6本书的内容安排
第2章主要介绍统计学习的基本技术和概念，这章还包括了一类原理简单却在许多领域运用自如的**$\mit{K}$最近邻**分类方法。

第3章主要回顾**线性回归**，这是所有回归方法的基础。

第4章讨论了两类重要的分类模型:**逻辑斯谛回归**和**线性判别分析**。

第5章重点介绍**交叉验证**和**自助法**，这些方法可通过估计不同方法的精度选择最优的模型。

第6章提供了一类集经典与现代于一体的线性模型，这些方法是在标准线性回归基础上的改进，包括**逐步变量选择、岭回归、主成分回归、偏最小二乘和lasso 回归**。

第7章首先介绍一类在一元输入变量问题中颇有成效的非线性方法，之后将说明这些方法如何被运用到多于一个输入变量的非线性**可加**模型中。

第8章重点考察树类模型，包括**装袋法**、**提升法**和**随机森林**。

第9章中介绍**支持向量机**，它是一种既可以用于线性分类，也可以用于非线性分类的一组方法

第10章考虑只有输入变量没有输出变量的一类方法，重点讲述**主成分分析**、 **$\mit{K}$均值聚类**和**系统聚类**方法。


## 1.7用于实验和习题的数据集
在这本教材中，我们将展现统计学习方法在各个领域的应用，这些领域包括市场营销、金融、生物和其他领域等。ISLR软件包可以从本书的网站下载，那里还有实验和习题用的数据集。其他的数据来自R的MASS库和R的基础数据。表 1-1 中列出了本书实验和习题所需要的数据集清单。读者也可以从该书的网站上下载这些数据集的文本格式，其中一些将在第2章使用。

## 1.8本书网站

[http://www - bcf. usc. edu/ ~ gareth/ISL/](http://faculty.marshall.usc.edu/gareth-james/ISL/)

## 1.9致谢
书中的图6-7、图8-3和图10-12来自ESL其他的图都是本书新增的。
